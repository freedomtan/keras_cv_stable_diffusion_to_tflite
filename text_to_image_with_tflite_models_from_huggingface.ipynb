{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/6vafBqsmzwQDT0ajUrLz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freedomtan/keras_cv_stable_diffusion_to_tflite/blob/main/text_to_image_with_tflite_models_from_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fFCC5ZNYk8n",
        "outputId": "903acbce-0aff-42d2-ff16-e266da40c70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-25 06:18:10--  https://huggingface.co/freedomtw/stable_diffusion_tflite/resolve/main/sd_text_encoder_dynamic.tflite\n",
            "Resolving huggingface.co (huggingface.co)... 52.2.178.255, 35.173.225.216, 54.82.45.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.2.178.255|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/5b/68/5b68dafa7260b5520ad69270750248074b5efdcc05386dff9cf0764d67893918/7f73c9b167fcda37c886cb4b382f65d13481ac24eb32ae88a18d5a5c0f933304?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_text_encoder_dynamic.tflite%3B+filename%3D%22sd_text_encoder_dynamic.tflite%22%3B&Expires=1679984291&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzViLzY4LzViNjhkYWZhNzI2MGI1NTIwYWQ2OTI3MDc1MDI0ODA3NGI1ZWZkY2MwNTM4NmRmZjljZjA3NjRkNjc4OTM5MTgvN2Y3M2M5YjE2N2ZjZGEzN2M4ODZjYjRiMzgyZjY1ZDEzNDgxYWMyNGViMzJhZTg4YTE4ZDVhNWMwZjkzMzMwND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2Nzk5ODQyOTF9fX1dfQ__&Signature=jnnAl4j4sGVVx1Bdt1hpzMxpg-NKItfVyJJnYVWkYk2AYpTZZAyQYOrWkEkwUCsiVRYRI2x94MwXav%7EfZlLwTX4kPR8H0cVWb5INVSdqSH7NZROGPwHL7WQmpwizLGscFGQ8v7prWfM%7ECCGeoKdCXtssMhE62V1Gi4pVV5i2gdlyuBv7zuhYcZNsXf5%7E1YyM7EhBI2xUQXCpIwS8lZM71PLk3HPTHdORrpfecLZL%7EC92VosUYz9bwaPwg-Yujl9IEv8EvhCpSJR2paq8TlnLRbYxWOsdrqJJHB7GxQB%7E5Ijbob%7EhYRa84dguKudb6MLRSQwfVIr0VMcnJlDSY7%7Ep1A__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-03-25 06:18:11--  https://cdn-lfs.huggingface.co/repos/5b/68/5b68dafa7260b5520ad69270750248074b5efdcc05386dff9cf0764d67893918/7f73c9b167fcda37c886cb4b382f65d13481ac24eb32ae88a18d5a5c0f933304?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_text_encoder_dynamic.tflite%3B+filename%3D%22sd_text_encoder_dynamic.tflite%22%3B&Expires=1679984291&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzViLzY4LzViNjhkYWZhNzI2MGI1NTIwYWQ2OTI3MDc1MDI0ODA3NGI1ZWZkY2MwNTM4NmRmZjljZjA3NjRkNjc4OTM5MTgvN2Y3M2M5YjE2N2ZjZGEzN2M4ODZjYjRiMzgyZjY1ZDEzNDgxYWMyNGViMzJhZTg4YTE4ZDVhNWMwZjkzMzMwND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2Nzk5ODQyOTF9fX1dfQ__&Signature=jnnAl4j4sGVVx1Bdt1hpzMxpg-NKItfVyJJnYVWkYk2AYpTZZAyQYOrWkEkwUCsiVRYRI2x94MwXav%7EfZlLwTX4kPR8H0cVWb5INVSdqSH7NZROGPwHL7WQmpwizLGscFGQ8v7prWfM%7ECCGeoKdCXtssMhE62V1Gi4pVV5i2gdlyuBv7zuhYcZNsXf5%7E1YyM7EhBI2xUQXCpIwS8lZM71PLk3HPTHdORrpfecLZL%7EC92VosUYz9bwaPwg-Yujl9IEv8EvhCpSJR2paq8TlnLRbYxWOsdrqJJHB7GxQB%7E5Ijbob%7EhYRa84dguKudb6MLRSQwfVIr0VMcnJlDSY7%7Ep1A__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.24.128, 13.35.24.87, 13.35.24.76, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123707568 (118M) [binary/octet-stream]\n",
            "Saving to: ‘sd_text_encoder_dynamic.tflite.1’\n",
            "\n",
            "sd_text_encoder_dyn 100%[===================>] 117.98M  20.7MB/s    in 6.9s    \n",
            "\n",
            "2023-03-25 06:18:19 (17.1 MB/s) - ‘sd_text_encoder_dynamic.tflite.1’ saved [123707568/123707568]\n",
            "\n",
            "--2023-03-25 06:18:19--  https://huggingface.co/freedomtw/stable_diffusion_tflite/resolve/main/sd_diffusion_model_dynamic.tflite\n",
            "Resolving huggingface.co (huggingface.co)... 52.2.178.255, 35.173.225.216, 54.82.45.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.2.178.255|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/5b/68/5b68dafa7260b5520ad69270750248074b5efdcc05386dff9cf0764d67893918/7548e14817d0d806b786bc7531c80f455127a7030a622ea26816ce8e467aaa4e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_diffusion_model_dynamic.tflite%3B+filename%3D%22sd_diffusion_model_dynamic.tflite%22%3B&Expires=1679984300&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzViLzY4LzViNjhkYWZhNzI2MGI1NTIwYWQ2OTI3MDc1MDI0ODA3NGI1ZWZkY2MwNTM4NmRmZjljZjA3NjRkNjc4OTM5MTgvNzU0OGUxNDgxN2QwZDgwNmI3ODZiYzc1MzFjODBmNDU1MTI3YTcwMzBhNjIyZWEyNjgxNmNlOGU0NjdhYWE0ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2Nzk5ODQzMDB9fX1dfQ__&Signature=GJJmLjfYqpscSNSe3f4JarT8tpLc5Eujlk8UFk1Q-ZRs4b8csnPzqbpTMTOZsz4kVHzCi08GCj48Ywzm-AIWdJOoYcev3eGEUi9YO7f9juP4mkH17Gehn1rdefth229Fyx4wgfy0YFOJioPBV-KGQ8NSA3EThvevya-xfeJAOe4oG5h36TNBsR-Fkwbwu4KUG5mfRDYsmZE1cZ93fSvKEI-8kQBoqItV7jDwOrObrN%7EDk5mBXjaJqj-V26-dfY9nwdgL%7EyE4hdxv-6JMPIqTshe91lrOmHGHheZ%7EWGjK4MUpaa7jdlrywHIHUBZJLgfLU-B-kcFLu2XOoKLSsL8D0Q__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-03-25 06:18:19--  https://cdn-lfs.huggingface.co/repos/5b/68/5b68dafa7260b5520ad69270750248074b5efdcc05386dff9cf0764d67893918/7548e14817d0d806b786bc7531c80f455127a7030a622ea26816ce8e467aaa4e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_diffusion_model_dynamic.tflite%3B+filename%3D%22sd_diffusion_model_dynamic.tflite%22%3B&Expires=1679984300&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzViLzY4LzViNjhkYWZhNzI2MGI1NTIwYWQ2OTI3MDc1MDI0ODA3NGI1ZWZkY2MwNTM4NmRmZjljZjA3NjRkNjc4OTM5MTgvNzU0OGUxNDgxN2QwZDgwNmI3ODZiYzc1MzFjODBmNDU1MTI3YTcwMzBhNjIyZWEyNjgxNmNlOGU0NjdhYWE0ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2Nzk5ODQzMDB9fX1dfQ__&Signature=GJJmLjfYqpscSNSe3f4JarT8tpLc5Eujlk8UFk1Q-ZRs4b8csnPzqbpTMTOZsz4kVHzCi08GCj48Ywzm-AIWdJOoYcev3eGEUi9YO7f9juP4mkH17Gehn1rdefth229Fyx4wgfy0YFOJioPBV-KGQ8NSA3EThvevya-xfeJAOe4oG5h36TNBsR-Fkwbwu4KUG5mfRDYsmZE1cZ93fSvKEI-8kQBoqItV7jDwOrObrN%7EDk5mBXjaJqj-V26-dfY9nwdgL%7EyE4hdxv-6JMPIqTshe91lrOmHGHheZ%7EWGjK4MUpaa7jdlrywHIHUBZJLgfLU-B-kcFLu2XOoKLSsL8D0Q__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.24.128, 13.35.24.87, 13.35.24.76, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 863125128 (823M) [binary/octet-stream]\n",
            "Saving to: ‘sd_diffusion_model_dynamic.tflite.1’\n",
            "\n",
            "sd_diffusion_model_ 100%[===================>] 823.14M  22.0MB/s    in 40s     \n",
            "\n",
            "2023-03-25 06:19:01 (20.5 MB/s) - ‘sd_diffusion_model_dynamic.tflite.1’ saved [863125128/863125128]\n",
            "\n",
            "--2023-03-25 06:19:01--  https://huggingface.co/freedomtw/stable_diffusion_tflite/resolve/main/sd_decoder_dynamic.tflite\n",
            "Resolving huggingface.co (huggingface.co)... 3.216.111.67, 54.82.45.103, 52.2.178.255, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.216.111.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/5b/68/5b68dafa7260b5520ad69270750248074b5efdcc05386dff9cf0764d67893918/dd01f1451c7855c0c14aad9eb8b15ed4e716eb80f2131f450325b80dbd0b0f02?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_decoder_dynamic.tflite%3B+filename%3D%22sd_decoder_dynamic.tflite%22%3B&Expires=1679984342&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzViLzY4LzViNjhkYWZhNzI2MGI1NTIwYWQ2OTI3MDc1MDI0ODA3NGI1ZWZkY2MwNTM4NmRmZjljZjA3NjRkNjc4OTM5MTgvZGQwMWYxNDUxYzc4NTVjMGMxNGFhZDllYjhiMTVlZDRlNzE2ZWI4MGYyMTMxZjQ1MDMyNWI4MGRiZDBiMGYwMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2Nzk5ODQzNDJ9fX1dfQ__&Signature=Fu3eoj4clsVKEiN5p4NkYstjbD689w0GagmA0FNXxKKiSUtVk2geUJJc%7EpXvZ6sFlOq4NQGminNSYOQbUovBs-f7piT1PYx7GKfQkpx63H938JcUvjHOzT%7EdUnvOUeiLiYsu9BU4hOOtg0CzVzydesPBMy4JijGyxRb4o6lOM89ywEm86lt6NpahkFUA4N42rRZcww4pdlOhAPRStNm2P2q8YM1j3CW3uxhJsBhttQizZ2iH0ZHTWy%7EQqxGPhq%7E6hSlEDzYWX9mJAW-vg5BJZnwjJNzWEUnJeeLQgIrwSz9t1MtQa8zxnPyEstpDHeNqzf-Saubvxb3N4hfkoOOxhw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-03-25 06:19:02--  https://cdn-lfs.huggingface.co/repos/5b/68/5b68dafa7260b5520ad69270750248074b5efdcc05386dff9cf0764d67893918/dd01f1451c7855c0c14aad9eb8b15ed4e716eb80f2131f450325b80dbd0b0f02?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_decoder_dynamic.tflite%3B+filename%3D%22sd_decoder_dynamic.tflite%22%3B&Expires=1679984342&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzViLzY4LzViNjhkYWZhNzI2MGI1NTIwYWQ2OTI3MDc1MDI0ODA3NGI1ZWZkY2MwNTM4NmRmZjljZjA3NjRkNjc4OTM5MTgvZGQwMWYxNDUxYzc4NTVjMGMxNGFhZDllYjhiMTVlZDRlNzE2ZWI4MGYyMTMxZjQ1MDMyNWI4MGRiZDBiMGYwMj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2Nzk5ODQzNDJ9fX1dfQ__&Signature=Fu3eoj4clsVKEiN5p4NkYstjbD689w0GagmA0FNXxKKiSUtVk2geUJJc%7EpXvZ6sFlOq4NQGminNSYOQbUovBs-f7piT1PYx7GKfQkpx63H938JcUvjHOzT%7EdUnvOUeiLiYsu9BU4hOOtg0CzVzydesPBMy4JijGyxRb4o6lOM89ywEm86lt6NpahkFUA4N42rRZcww4pdlOhAPRStNm2P2q8YM1j3CW3uxhJsBhttQizZ2iH0ZHTWy%7EQqxGPhq%7E6hSlEDzYWX9mJAW-vg5BJZnwjJNzWEUnJeeLQgIrwSz9t1MtQa8zxnPyEstpDHeNqzf-Saubvxb3N4hfkoOOxhw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.24.128, 13.35.24.87, 13.35.24.38, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50055816 (48M) [binary/octet-stream]\n",
            "Saving to: ‘sd_decoder_dynamic.tflite.1’\n",
            "\n",
            "sd_decoder_dynamic. 100%[===================>]  47.74M  14.5MB/s    in 3.3s    \n",
            "\n",
            "2023-03-25 06:19:06 (14.5 MB/s) - ‘sd_decoder_dynamic.tflite.1’ saved [50055816/50055816]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/freedomtw/stable_diffusion_tflite/resolve/main/sd_text_encoder_dynamic.tflite\n",
        "!wget https://huggingface.co/freedomtw/stable_diffusion_tflite/resolve/main/sd_diffusion_model_dynamic.tflite\n",
        "!wget https://huggingface.co/freedomtw/stable_diffusion_tflite/resolve/main/sd_decoder_dynamic.tflite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_cv\n",
        "!pip install -U tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPTxowIqZzxm",
        "outputId": "010e00f9-32f2-4751-dc76-6a8b5891cc43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_cv in /usr/local/lib/python3.9/dist-packages (0.4.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from keras_cv) (2022.10.31)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.9/dist-packages (from keras_cv) (4.8.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_cv) (23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (8.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (1.22.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (2.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (2.27.1)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (1.1.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (5.9.4)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (4.65.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv) (4.5.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv) (5.12.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (1.26.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.59.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWPGmH-sY-W-",
        "outputId": "6d22f8a0-8fa1-48ce-b44f-106332f81629"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the Keras CV pipeline, we need the tokenizer\n",
        "\n",
        "model = keras_cv.models.StableDiffusion(512, 512)\n",
        "tokenizer = model.tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X-fWOc2aGNT",
        "outputId": "c74b766c-0744-4ca2-b5b3-2d68870e27ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# most of the code is from Keras CV implementation, \n",
        "# https://github.com/keras-team/keras-cv/blob/v0.4.1/keras_cv/models/stable_diffusion/stable_diffusion.py,\n",
        "# not fully implmented, just to show that converted models work\n",
        "\n",
        "# also borrow constants from keras cv\n",
        "from keras_cv.models.stable_diffusion.constants import _UNCONDITIONAL_TOKENS\n",
        "from keras_cv.models.stable_diffusion.constants import _ALPHAS_CUMPROD\n",
        "\n",
        "class StableDiffusionTFLite:\n",
        "    MAX_PROMPT_LENGTH = 77\n",
        "    img_height = 512\n",
        "    img_width = 512\n",
        "    \n",
        "    def _get_initial_alphas(self, timesteps):\n",
        "        alphas = [_ALPHAS_CUMPROD[t] for t in timesteps]\n",
        "        alphas_prev = [1.0] + alphas[:-1]\n",
        "\n",
        "        return alphas, alphas_prev\n",
        "    \n",
        "    def _get_initial_diffusion_noise(self, batch_size, seed):\n",
        "        if seed is not None:\n",
        "            return tf.random.stateless_normal(\n",
        "                (batch_size, self.img_height // 8, self.img_width // 8, 4),\n",
        "                seed=[seed, seed],\n",
        "            )\n",
        "        else:\n",
        "            return tf.random.normal(\n",
        "                (batch_size, self.img_height // 8, self.img_width // 8, 4)\n",
        "            )\n",
        "        \n",
        "    def _get_timestep_embedding(self, timestep, batch_size, dim=320, max_period=10000):\n",
        "        half = dim // 2\n",
        "        freqs = tf.math.exp(\n",
        "            -math.log(max_period) * tf.range(0, half, dtype=tf.float32) / half\n",
        "        )\n",
        "        args = tf.convert_to_tensor([timestep], dtype=tf.float32) * freqs\n",
        "        embedding = tf.concat([tf.math.cos(args), tf.math.sin(args)], 0)\n",
        "        embedding = tf.reshape(embedding, [1, -1])\n",
        "        return tf.repeat(embedding, batch_size, axis=0)\n",
        "\n",
        "    def _get_pos_ids(self):\n",
        "        return tf.convert_to_tensor([list(range(self.MAX_PROMPT_LENGTH))], dtype=tf.int32)\n",
        "\n",
        "    def encoded_token_padded(self, prompt):\n",
        "        inputs = tokenizer.encode(prompt)\n",
        "        phrase = inputs + [49407] * (self.MAX_PROMPT_LENGTH - len(inputs))\n",
        "        phrase = tf.convert_to_tensor([phrase], dtype=tf.int32)\n",
        "\n",
        "        return phrase, self._get_pos_ids()\n",
        "    \n",
        "    def encode_text(self, prompt):\n",
        "        i_text_encoder = tf.lite.Interpreter('sd_text_encoder_dynamic.tflite')\n",
        "        i_text_encoder.allocate_tensors()\n",
        "        input_details = i_text_encoder.get_input_details()\n",
        "        output_details = i_text_encoder.get_output_details()\n",
        "\n",
        "        token, pos = self.encoded_token_padded(prompt)\n",
        "        i_text_encoder.set_tensor(input_details[0]['index'], token)\n",
        "        i_text_encoder.set_tensor(input_details[1]['index'], pos)\n",
        "\n",
        "        i_text_encoder.invoke()\n",
        "\n",
        "        output_data = i_text_encoder.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        return output_data\n",
        "    \n",
        "    def encode_text_2(self, token, pos):\n",
        "        i_text_encoder = tf.lite.Interpreter('sd_text_encoder_dynamic.tflite')\n",
        "        \n",
        "        i_text_encoder.allocate_tensors()\n",
        "        \n",
        "        input_details = i_text_encoder.get_input_details()\n",
        "        output_details = i_text_encoder.get_output_details()\n",
        "\n",
        "        i_text_encoder.set_tensor(input_details[0]['index'], token)\n",
        "        i_text_encoder.set_tensor(input_details[1]['index'], pos)\n",
        "\n",
        "        i_text_encoder.invoke()\n",
        "\n",
        "        output_data = i_text_encoder.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        return output_data\n",
        "\n",
        "\n",
        "    def _expand_tensor(self, text_embedding, batch_size):\n",
        "        \"\"\"Extends a tensor by repeating it to fit the shape of the given batch size.\"\"\"\n",
        "        text_embedding = tf.squeeze(text_embedding)\n",
        "        if text_embedding.shape.rank == 2:\n",
        "            text_embedding = tf.repeat(\n",
        "                tf.expand_dims(text_embedding, axis=0), batch_size, axis=0\n",
        "            )\n",
        "        return text_embedding\n",
        "    \n",
        "    def _get_unconditional_context(self):\n",
        "        unconditional_tokens = tf.convert_to_tensor(\n",
        "            [_UNCONDITIONAL_TOKENS], dtype=tf.int32\n",
        "        )\n",
        "        unconditional_context = self.encode_text_2(unconditional_tokens, self._get_pos_ids())\n",
        "        return unconditional_context\n",
        "    \n",
        "    def diffusion_model(self, latent, t_emb, unconditional_context):\n",
        "        i_diffusion = tf.lite.Interpreter('sd_diffusion_model_dynamic.tflite')\n",
        "\n",
        "        i_diffusion_input_details = i_diffusion.get_input_details()\n",
        "        i_diffusion_output_details = i_diffusion.get_output_details()\n",
        "        \n",
        "        i_diffusion.resize_tensor_input(i_diffusion_input_details[0]['index'], latent.shape)\n",
        "        i_diffusion.resize_tensor_input(i_diffusion_input_details[1]['index'], t_emb.shape)\n",
        "        i_diffusion.resize_tensor_input(i_diffusion_input_details[2]['index'], unconditional_context.shape)\n",
        "\n",
        "        i_diffusion.allocate_tensors()\n",
        "\n",
        "        i_diffusion.set_tensor(i_diffusion_input_details[0]['index'], latent)\n",
        "        i_diffusion.set_tensor(i_diffusion_input_details[1]['index'], t_emb)\n",
        "        i_diffusion.set_tensor(i_diffusion_input_details[2]['index'], unconditional_context)\n",
        "\n",
        "        i_diffusion.invoke()\n",
        "        \n",
        "        output_data = i_diffusion.get_tensor(i_diffusion_output_details[0]['index'])\n",
        "        \n",
        "        return output_data\n",
        "    \n",
        "    def decode(self, encoded_image):\n",
        "        i_decoder = tf.lite.Interpreter('sd_decoder_dynamic.tflite')\n",
        "        \n",
        "        input_details = i_decoder.get_input_details()\n",
        "        output_details = i_decoder.get_output_details()\n",
        "        \n",
        "        i_decoder.resize_tensor_input(input_details[0]['index'], encoded_image.shape)\n",
        "        \n",
        "        i_decoder.allocate_tensors()\n",
        "        \n",
        "        i_decoder.set_tensor(input_details[0]['index'], encoded_image)\n",
        "        i_decoder.invoke()\n",
        "        output_data = i_decoder.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        return output_data\n",
        "\n",
        "    def generate_image(\n",
        "        self,\n",
        "        encoded_text,\n",
        "        negative_prompt=None,\n",
        "        batch_size=1,\n",
        "        num_steps=50,\n",
        "        unconditional_guidance_scale=7.5,\n",
        "        diffusion_noise=None,\n",
        "        seed=None,\n",
        "    ):\n",
        "        context = self._expand_tensor(encoded_text, batch_size)\n",
        "\n",
        "        if negative_prompt is None:\n",
        "            unconditional_context = tf.repeat(\n",
        "                self._get_unconditional_context(), batch_size, axis=0\n",
        "            )\n",
        "        else:\n",
        "            unconditional_context = self.encode_text(negative_prompt)\n",
        "            unconditional_context = self._expand_tensor(\n",
        "                unconditional_context, batch_size\n",
        "            )\n",
        "        if diffusion_noise is not None:\n",
        "            diffusion_noise = tf.squeeze(diffusion_noise)\n",
        "            if diffusion_noise.shape.rank == 3:\n",
        "                diffusion_noise = tf.repeat(\n",
        "                    tf.expand_dims(diffusion_noise, axis=0), batch_size, axis=0\n",
        "                )\n",
        "            latent = diffusion_noise\n",
        "        else:\n",
        "            latent = self._get_initial_diffusion_noise(batch_size, seed)\n",
        "\n",
        "        timesteps = tf.range(1, 1000, 1000 // num_steps)\n",
        "        alphas, alphas_prev = self._get_initial_alphas(timesteps)\n",
        "        progbar = keras.utils.Progbar(len(timesteps))\n",
        "        iteration = 0\n",
        "        for index, timestep in list(enumerate(timesteps))[::-1]:\n",
        "            latent_prev = latent  # Set aside the previous latent vector\n",
        "            t_emb = self._get_timestep_embedding(timestep, batch_size)\n",
        "            unconditional_latent = self.diffusion_model(latent, t_emb, unconditional_context)\n",
        "            \n",
        "            latent = self.diffusion_model(latent, t_emb, context)\n",
        "            latent = unconditional_latent + unconditional_guidance_scale * (\n",
        "                latent - unconditional_latent\n",
        "            )\n",
        "            a_t, a_prev = alphas[index], alphas_prev[index]\n",
        "            pred_x0 = (latent_prev - math.sqrt(1 - a_t) * latent) / math.sqrt(a_t)\n",
        "            latent = latent * math.sqrt(1.0 - a_prev) + math.sqrt(a_prev) * pred_x0\n",
        "            iteration += 1\n",
        "            progbar.update(iteration)\n",
        "\n",
        "        # Decoding stage\n",
        "        decoded = self.decode(latent)\n",
        "        decoded = ((decoded + 1) / 2) * 255\n",
        "        return np.clip(decoded, 0, 255).astype(\"uint8\")"
      ],
      "metadata": {
        "id": "p3ZzBRxGZyly"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_t = StableDiffusionTFLite()\n",
        "encoded_text_tflite = model_t.encode_text('a photo of an astronaut riding a horse on Mars')\n",
        "f = model_t.generate_image(encoded_text_tflite, num_steps=25, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "zrXs3uNJaUEM",
        "outputId": "1784668a-05a4-4902-f317-e9fabc0cbff6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 4/25 [===>..........................] - ETA: 32:41"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fd5bc5e566dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStableDiffusionTFLite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoded_text_tflite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a photo of an astronaut riding a horse on Mars'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text_tflite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-94e2f42d4bfb>\u001b[0m in \u001b[0;36mgenerate_image\u001b[0;34m(self, encoded_text, negative_prompt, batch_size, num_steps, unconditional_guidance_scale, diffusion_noise, seed)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0munconditional_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munconditional_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             latent = unconditional_latent + unconditional_guidance_scale * (\n\u001b[1;32m    181\u001b[0m                 \u001b[0mlatent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0munconditional_latent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-94e2f42d4bfb>\u001b[0m in \u001b[0;36mdiffusion_model\u001b[0;34m(self, latent, t_emb, unconditional_context)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mi_diffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_diffusion_input_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munconditional_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mi_diffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_diffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_diffusion_output_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \"\"\"\n\u001b[1;32m    916\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.fromarray(tf.squeeze(f[0]).numpy())"
      ],
      "metadata": {
        "id": "D5wMS4pNaYfX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
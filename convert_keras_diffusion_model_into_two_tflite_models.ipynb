{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53ef16-9441-427e-aa27-afe6f83c7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffa7b3-95fb-4d05-9aad-bc2fb01ff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pipeline, then get the diffusion/denoise mode\n",
    "\n",
    "model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)\n",
    "diffusion_model = model.diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc3869-cf43-4600-8460-b907c57f819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the op/layer that we can use to split the model into two roughly equal chunks\n",
    "\n",
    "def find_split_layer(model):\n",
    "    total_size = 0\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if layer.weights:\n",
    "            # print(layer.name)\n",
    "            if (isinstance(layer.weights, list)):\n",
    "                  for w in layer.weights:\n",
    "                    # print(w.shape, w.dtype)\n",
    "                    total_size = total_size + w.numpy().size\n",
    "    # print(\"total size:\", total_size)\n",
    "    half_size = total_size / 2\n",
    "\n",
    "    first_layers = []\n",
    "    accumulator = 0 \n",
    "    for layer in model.layers:\n",
    "        first_layers.append(layer.name)\n",
    "        # print(first_layers)\n",
    "        if layer.weights:\n",
    "            if (isinstance(layer.weights, list)):\n",
    "                for w in layer.weights:\n",
    "                    accumulator = accumulator + w.numpy().size\n",
    "                if accumulator > half_size:\n",
    "                    return first_layers, layer.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the edges crossing both chunks\n",
    "# use them as the output tensors of the first chunk and the input tensors of the second chunk\n",
    "\n",
    "def find_boundary_tensors(model, first_layers, end_of_first_chunk):\n",
    "    \n",
    "    boundary_tensors = []\n",
    "    boundary_input_layers = []\n",
    "    in_second_chunk = False\n",
    "    \n",
    "    for l in model.layers:\n",
    "        if in_second_chunk:\n",
    "            #print(l.name)\n",
    "            if (isinstance(l.input, list)):\n",
    "                for i in l.input:\n",
    "                    #print(\"  \", i.node.layer.name)\n",
    "                    if (i.node.layer.name in first_layers):\n",
    "                        #print(\"  \", i.node.layer.name)\n",
    "                        #print(boundary_input_layers)\n",
    "                        if (i.node.layer.name not in boundary_input_layers):\n",
    "                            # print(boundary_tensors)\n",
    "                            boundary_tensors.append(i)\n",
    "                            boundary_input_layers.append(i.node.layer.name)\n",
    "            else:\n",
    "                # print(\"  whatever\", l.input.node.layer.name)\n",
    "                if (l.input.node.layer.name in first_layers):\n",
    "                    # print(\"  yes:\", l.input.layer.name)\n",
    "                    boundary_tensors.append(l.input)\n",
    "                    boundary_input_layers.append(i.input.name)\n",
    "                    \n",
    "        elif (l.name == end_of_first_chunk):\n",
    "            in_second_chunk = True\n",
    "            \n",
    "    return boundary_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93227d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layers, end_of_first_chunk = find_split_layer(diffusion_model)\n",
    "boundary_tensors = find_boundary_tensors(diffusion_model, first_layers, end_of_first_chunk)\n",
    "\n",
    "# construct the two chunks\n",
    "first_part = keras.Model(diffusion_model.inputs, boundary_tensors)\n",
    "second_part = keras.Model(boundary_tensors, diffusion_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the two chunks to tflite\n",
    "\n",
    "converter1 = tf.lite.TFLiteConverter.from_keras_model(first_part)\n",
    "chunk1 = converter1.convert()\n",
    "with open('/tmp/sd_diffusion_model_first.tflite', 'wb') as f:\n",
    "    f.write(chunk1)\n",
    "    \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(second_part)\n",
    "chunk2 = converter2.convert()\n",
    "with open('/tmp/sd_diffusion_model_second.tflite', 'wb') as f:\n",
    "    f.write(chunk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cc23d-3955-4c89-b5eb-3e949bca04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part.save('/tmp/sd/diffusion_model_first')\n",
    "second_part.save('/tmp/sd/diffusion_model_second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509524b7-b61c-4105-9d9b-ede0b71f288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = tf.saved_model.load('/tmp/sd/diffusion_model_first/')\n",
    "\n",
    "concrete_func = first_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "concrete_func.inputs[0].set_shape([1, 77, 768])\n",
    "concrete_func.inputs[1].set_shape([1, 320])\n",
    "concrete_func.inputs[2].set_shape([1, 64, 64, 4])\n",
    "converter1 = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "first_model_fixed_size = converter1.convert()\n",
    "\n",
    "with open('/tmp/sd_diffusion_model_first_fixed_batch.tflite', 'wb') as f:\n",
    "    f.write(first_model_fixed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969a720-394b-417a-839d-b92d0e5558d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = tf.saved_model.load('/tmp/sd/diffusion_model_second/')\n",
    "\n",
    "concrete_func_2 = second_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "\n",
    "concrete_func_2.inputs[0].set_shape([1, 8, 8, 1280])\n",
    "concrete_func_2.inputs[1].set_shape([1, 8, 8, 1280])\n",
    "concrete_func_2.inputs[2].set_shape([1, 64, 64, 320])\n",
    "concrete_func_2.inputs[3].set_shape([1, 64, 64, 320])\n",
    "concrete_func_2.inputs[4].set_shape([1, 64, 64, 320])\n",
    "concrete_func_2.inputs[5].set_shape([1, 1280])\n",
    "concrete_func_2.inputs[6].set_shape([1, 16, 16, 1280])\n",
    "concrete_func_2.inputs[7].set_shape([1, 77, 768])\n",
    "concrete_func_2.inputs[8].set_shape([1, 16, 16, 1280])\n",
    "concrete_func_2.inputs[9].set_shape([1, 16, 16, 640])\n",
    "concrete_func_2.inputs[10].set_shape([1, 32, 32, 640])\n",
    "concrete_func_2.inputs[11].set_shape([1, 32, 32, 640])\n",
    "concrete_func_2.inputs[12].set_shape([1, 32, 32, 320])\n",
    "\n",
    "converter2 = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func_2])\n",
    "second_model_fixed_size = converter2.convert()\n",
    "\n",
    "with open('/tmp/sd_diffusion_model_second_fixed_batch.tflite', 'wb') as f:\n",
    "    f.write(second_model_fixed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e00145-026f-4bdd-8f5e-f1049265d1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
